{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "pd.set_option('display.max_colwidth', -1) # damit der komplette Output im Notebook angezeigt wird"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1b07f7d21eed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_colwidth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# damit der komplette Output im Notebook angezeigt wird\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parrot Libary Test (Pretrained Model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from parrot import Parrot\r\n",
    "import torch\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def random_state(seed):\r\n",
    "    torch.manual_seed(seed)\r\n",
    "    if torch.cuda.is_available():\r\n",
    "        torch.cuda.manual_seed_all(seed)\r\n",
    "\r\n",
    "random_state(1234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "phrases = [\"a suit for a casual meeting\", \"beautiful dresses\", \"a t-shirt with logo print\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for phrase in phrases:\r\n",
    "    print(\"\\n\", \"-\"*100)\r\n",
    "    print(\"Input_phrase: \", phrase)\r\n",
    "    print(\"-\"*100)\r\n",
    "    para_phrases = parrot.augment(input_phrase=phrase)\r\n",
    "    for para_phrase in para_phrases:\r\n",
    "        print(para_phrase)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  a suit for a casual meeting\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('dress for casual meetings', 18)\n",
      "('a suit for a casual meeting', 12)\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  beautiful dresses\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('wonderful dresses', 17)\n",
      "('pretty dresses', 17)\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  a t-shirt with logo print\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('a t-shirt with the logo printed', 18)\n",
      "('a t-shirt with logo print', 12)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BART selbst trainieren"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from datetime import datetime\r\n",
    "import logging\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import warnings\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "\r\n",
    "def load_data(\r\n",
    "    file_path, input_text_column, target_text_column, label_column, keep_label=1\r\n",
    "):\r\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", error_bad_lines=False)\r\n",
    "    df = df.loc[df[label_column] == keep_label]\r\n",
    "    df = df.rename(\r\n",
    "        columns={input_text_column: \"input_text\", target_text_column: \"target_text\"}\r\n",
    "    )\r\n",
    "    df = df[[\"input_text\", \"target_text\"]]\r\n",
    "    df[\"prefix\"] = \"paraphrase\"\r\n",
    "\r\n",
    "    return df\r\n",
    "\r\n",
    "\r\n",
    "def clean_unnecessary_spaces(out_string):\r\n",
    "    if not isinstance(out_string, str):\r\n",
    "        warnings.warn(f\">>> {out_string} <<< is not a string.\")\r\n",
    "        out_string = str(out_string)\r\n",
    "    out_string = (\r\n",
    "        out_string.replace(\" .\", \".\")\r\n",
    "        .replace(\" ?\", \"?\")\r\n",
    "        .replace(\" !\", \"!\")\r\n",
    "        .replace(\" ,\", \",\")\r\n",
    "        .replace(\" ' \", \"'\")\r\n",
    "        .replace(\" n't\", \"n't\")\r\n",
    "        .replace(\" 'm\", \"'m\")\r\n",
    "        .replace(\" 's\", \"'s\")\r\n",
    "        .replace(\" 've\", \"'ve\")\r\n",
    "        .replace(\" 're\", \"'re\")\r\n",
    "    )\r\n",
    "    return out_string\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "logging.basicConfig(level=logging.INFO)\r\n",
    "transformers_logger = logging.getLogger(\"transformers\")\r\n",
    "transformers_logger.setLevel(logging.ERROR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Google Data\r\n",
    "train_df = pd.read_csv(\"data/train.tsv\", sep=\"\\t\").astype(str)\r\n",
    "eval_df = pd.read_csv(\"data/dev.tsv\", sep=\"\\t\").astype(str)\r\n",
    "\r\n",
    "train_df = train_df.loc[train_df[\"label\"] == \"1\"]\r\n",
    "eval_df = eval_df.loc[eval_df[\"label\"] == \"1\"]\r\n",
    "\r\n",
    "train_df = train_df.rename(\r\n",
    "    columns={\"sentence1\": \"input_text\", \"sentence2\": \"target_text\"}\r\n",
    ")\r\n",
    "eval_df = eval_df.rename(\r\n",
    "    columns={\"sentence1\": \"input_text\", \"sentence2\": \"target_text\"}\r\n",
    ")\r\n",
    "\r\n",
    "train_df = train_df[[\"input_text\", \"target_text\"]]\r\n",
    "eval_df = eval_df[[\"input_text\", \"target_text\"]]\r\n",
    "\r\n",
    "train_df[\"prefix\"] = \"paraphrase\"\r\n",
    "eval_df[\"prefix\"] = \"paraphrase\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(train_df.shape)\r\n",
    "print(eval_df.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(21829, 3)\n",
      "(3539, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(train_df.iloc[:1]['input_text'])\r\n",
    "print(train_df.iloc[:1]['target_text'])\r\n",
    "print(eval_df.iloc[:1]['input_text'])\r\n",
    "print(eval_df.iloc[:1]['target_text'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1    The NBA season of 1975 -- 76 was the 30th seas...\n",
      "Name: input_text, dtype: object\n",
      "1    The 1975 -- 76 season of the National Basketba...\n",
      "Name: target_text, dtype: object\n",
      "1    They were there to enjoy us and they were ther...\n",
      "Name: input_text, dtype: object\n",
      "1    They were there for us to enjoy and they were ...\n",
      "Name: target_text, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# MSRP Data\r\n",
    "train_df = pd.concat(\r\n",
    "    [\r\n",
    "        train_df,\r\n",
    "        load_data(\"data/msr_paraphrase_train.txt\", \"#1 String\", \"#2 String\", \"Quality\"),\r\n",
    "    ]\r\n",
    ")\r\n",
    "eval_df = pd.concat(\r\n",
    "    [\r\n",
    "        eval_df,\r\n",
    "        load_data(\"data/msr_paraphrase_test.txt\", \"#1 String\", \"#2 String\", \"Quality\"),\r\n",
    "    ]\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "b'Skipping line 102: expected 5 fields, saw 6\\nSkipping line 656: expected 5 fields, saw 6\\nSkipping line 867: expected 5 fields, saw 6\\nSkipping line 880: expected 5 fields, saw 6\\nSkipping line 980: expected 5 fields, saw 6\\nSkipping line 1439: expected 5 fields, saw 6\\nSkipping line 1473: expected 5 fields, saw 6\\nSkipping line 1822: expected 5 fields, saw 6\\nSkipping line 1952: expected 5 fields, saw 6\\nSkipping line 2009: expected 5 fields, saw 6\\nSkipping line 2230: expected 5 fields, saw 6\\nSkipping line 2506: expected 5 fields, saw 6\\nSkipping line 2523: expected 5 fields, saw 6\\nSkipping line 2809: expected 5 fields, saw 6\\nSkipping line 2887: expected 5 fields, saw 6\\nSkipping line 2920: expected 5 fields, saw 6\\nSkipping line 2944: expected 5 fields, saw 6\\nSkipping line 3241: expected 5 fields, saw 6\\nSkipping line 3358: expected 5 fields, saw 6\\nSkipping line 3459: expected 5 fields, saw 6\\nSkipping line 3491: expected 5 fields, saw 6\\nSkipping line 3643: expected 5 fields, saw 6\\nSkipping line 3696: expected 5 fields, saw 6\\nSkipping line 3955: expected 5 fields, saw 6\\n'\n",
      "b'Skipping line 34: expected 5 fields, saw 6\\nSkipping line 121: expected 5 fields, saw 6\\nSkipping line 211: expected 5 fields, saw 6\\nSkipping line 263: expected 5 fields, saw 6\\nSkipping line 345: expected 5 fields, saw 6\\nSkipping line 696: expected 5 fields, saw 6\\nSkipping line 733: expected 5 fields, saw 6\\nSkipping line 847: expected 5 fields, saw 6\\nSkipping line 1392: expected 5 fields, saw 6\\nSkipping line 1467: expected 5 fields, saw 6\\nSkipping line 1551: expected 5 fields, saw 6\\n'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Quora Data\r\n",
    "\r\n",
    "# The Quora Dataset is not separated into train/test, so we do it manually the first time.\r\n",
    "# df = load_data(\r\n",
    "#     \"data/quora_duplicate_questions.tsv\", \"question1\", \"question2\", \"is_duplicate\"\r\n",
    "# )\r\n",
    "# q_train, q_test = train_test_split(df)\r\n",
    "\r\n",
    "# q_train.to_csv(\"data/quora_train.tsv\", sep=\"\\t\")\r\n",
    "# q_test.to_csv(\"data/quora_test.tsv\", sep=\"\\t\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "q_train = pd.read_csv(\"data/quora_train.tsv\", sep=\"\\t\")\r\n",
    "q_test = pd.read_csv(\"data/quora_test.tsv\", sep=\"\\t\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_df = pd.concat([train_df, q_train])\r\n",
    "eval_df = pd.concat([eval_df, q_test])\r\n",
    "\r\n",
    "train_df = train_df[[\"prefix\", \"input_text\", \"target_text\"]]\r\n",
    "eval_df = eval_df[[\"prefix\", \"input_text\", \"target_text\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train_df = train_df.dropna()\r\n",
    "eval_df = eval_df.dropna()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "train_df[\"input_text\"] = train_df[\"input_text\"].apply(clean_unnecessary_spaces)\r\n",
    "train_df[\"target_text\"] = train_df[\"target_text\"].apply(clean_unnecessary_spaces)\r\n",
    "\r\n",
    "eval_df[\"input_text\"] = eval_df[\"input_text\"].apply(clean_unnecessary_spaces)\r\n",
    "eval_df[\"target_text\"] = eval_df[\"target_text\"].apply(clean_unnecessary_spaces)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(train_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            prefix                                         input_text  \\\n",
      "1       paraphrase  The NBA season of 1975 -- 76 was the 30th seas...   \n",
      "3       paraphrase  When comparable rates of flow can be maintaine...   \n",
      "4       paraphrase  It is the seat of Zerendi District in Akmola R...   \n",
      "5       paraphrase  William Henry Henry Harman was born on 17 Febr...   \n",
      "7       paraphrase  With a discrete amount of probabilities Formul...   \n",
      "...            ...                                                ...   \n",
      "111942  paraphrase  What was the craziest dream that you've ever had?   \n",
      "111943  paraphrase             How do I increase height at age of 16?   \n",
      "111944  paraphrase  If superconductors have infinite permeability ...   \n",
      "111945  paraphrase  How can I contact someone on Quora and send pr...   \n",
      "111946  paraphrase  Why should Jayalalittha be awarded by Bharat R...   \n",
      "\n",
      "                                              target_text  \n",
      "1       The 1975 -- 76 season of the National Basketba...  \n",
      "3       The results are high when comparable flow rate...  \n",
      "4       It is the seat of the district of Zerendi in A...  \n",
      "5       William Henry Harman was born in Waynesboro, V...  \n",
      "7       Given a discrete set of probabilities formula ...  \n",
      "...                                                   ...  \n",
      "111942       Which is the weirdest dream youâ€™ve ever had?  \n",
      "111943  My age in 22 and my height is 5'5 I want more ...  \n",
      "111944  If superconductors have infinite permeability ...  \n",
      "111945  Is it possible to send messages privately thro...  \n",
      "111946  What are your views on Jayalalitha's name reco...  \n",
      "\n",
      "[136422 rows x 3 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_args = Seq2SeqArgs()\r\n",
    "model_args.eval_batch_size = 64\r\n",
    "model_args.evaluate_during_training = True\r\n",
    "model_args.evaluate_during_training_steps = 2500\r\n",
    "model_args.evaluate_during_training_verbose = True\r\n",
    "model_args.fp16 = False\r\n",
    "model_args.learning_rate = 5e-5\r\n",
    "model_args.max_seq_length = 128\r\n",
    "model_args.num_train_epochs = 2\r\n",
    "model_args.overwrite_output_dir = True\r\n",
    "model_args.reprocess_input_data = True\r\n",
    "model_args.save_eval_checkpoints = False\r\n",
    "model_args.save_steps = -1\r\n",
    "model_args.train_batch_size = 8\r\n",
    "model_args.use_multiprocessing = False\r\n",
    "\r\n",
    "model_args.do_sample = True\r\n",
    "model_args.num_beams = None\r\n",
    "model_args.num_return_sequences = 3\r\n",
    "model_args.max_length = 128\r\n",
    "model_args.top_k = 50\r\n",
    "model_args.top_p = 0.95\r\n",
    "\r\n",
    "model_args.wandb_project = \"Paraphrasing with BART\"\r\n",
    "model_args.WANDB_NOTEBOOK_NAME = \"Paraphrasing for Semantic Search\"\r\n",
    "\r\n",
    "\r\n",
    "model = Seq2SeqModel(\r\n",
    "    encoder_decoder_type=\"bart\",\r\n",
    "    encoder_decoder_name=\"facebook/bart-large\",\r\n",
    "    args=model_args,\r\n",
    ")\r\n",
    "\r\n",
    "model.train_model(train_df, eval_data=eval_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "to_predict = [\r\n",
    "    prefix + \": \" + str(input_text)\r\n",
    "    for prefix, input_text in zip(\r\n",
    "        eval_df[\"prefix\"].tolist(), eval_df[\"input_text\"].tolist()\r\n",
    "    )\r\n",
    "]\r\n",
    "truth = eval_df[\"target_text\"].tolist()\r\n",
    "\r\n",
    "preds = model.predict(to_predict)\r\n",
    "\r\n",
    "# Saving the predictions if needed\r\n",
    "os.makedirs(\"predictions\", exist_ok=True)\r\n",
    "\r\n",
    "with open(f\"predictions/predictions_{datetime.now()}.txt\", \"w\") as f:\r\n",
    "    for i, text in enumerate(eval_df[\"input_text\"].tolist()):\r\n",
    "        f.write(str(text) + \"\\n\\n\")\r\n",
    "\r\n",
    "        f.write(\"Truth:\\n\")\r\n",
    "        f.write(truth[i] + \"\\n\\n\")\r\n",
    "\r\n",
    "        f.write(\"Prediction:\\n\")\r\n",
    "        for pred in preds[i]:\r\n",
    "            f.write(str(pred) + \"\\n\")\r\n",
    "        f.write(\r\n",
    "            \"________________________________________________________________________________\\n\"\r\n",
    "        )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pretrained Sentence Transformers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import json\r\n",
    "import pandas as pd\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "with open(r\"E:\\Users\\Lucas xD\\Downloads\\Products_Q_US_edited.json\", encoding=\"utf8\") as json_file:\r\n",
    "    data = json.load(json_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df = pd.json_normalize(data)\r\n",
    "df = df.drop(columns=['brand', 'colors', 'gender', 'productId', 'sizes', 'styleName', 'variants', 'image', 'id', 'longDescription'])\r\n",
    "\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               name  \\\n",
       "0          Stretch Cotton V-Neck T-Shirt | Dredosos   \n",
       "1                 Leather belt with embossed detail   \n",
       "2         Italian Leather Derby Dress Shoe | Prindo   \n",
       "3   Virgin Wool Tuxedo, Regular Fit | Stars/Glamour   \n",
       "4  Italian Virgin Wool Suit, Slim Fit | Huge/Genius   \n",
       "\n",
       "                                    shortDescription  \n",
       "0  This t-shirt by HUGO is crafted from cotton wi...  \n",
       "1  Upgrade your everyday collection with this tim...  \n",
       "2  Crafted from fine Italian calfskin with a prin...  \n",
       "3  This regular fit tuxedo by BOSS is crafted in ...  \n",
       "4  Our best-selling suit just got better with an ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shortDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stretch Cotton V-Neck T-Shirt | Dredosos</td>\n",
       "      <td>This t-shirt by HUGO is crafted from cotton wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leather belt with embossed detail</td>\n",
       "      <td>Upgrade your everyday collection with this tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italian Leather Derby Dress Shoe | Prindo</td>\n",
       "      <td>Crafted from fine Italian calfskin with a prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virgin Wool Tuxedo, Regular Fit | Stars/Glamour</td>\n",
       "      <td>This regular fit tuxedo by BOSS is crafted in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italian Virgin Wool Suit, Slim Fit | Huge/Genius</td>\n",
       "      <td>Our best-selling suit just got better with an ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "df = df.stack().reset_index() # all in one column\r\n",
    "df = df.drop(columns=['level_0', 'level_1'])\r\n",
    "df.columns = ['sentences']\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           sentences\n",
       "0           Stretch Cotton V-Neck T-Shirt | Dredosos\n",
       "1  This t-shirt by HUGO is crafted from cotton wi...\n",
       "2                  Leather belt with embossed detail\n",
       "3  Upgrade your everyday collection with this tim...\n",
       "4          Italian Leather Derby Dress Shoe | Prindo"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stretch Cotton V-Neck T-Shirt | Dredosos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This t-shirt by HUGO is crafted from cotton wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leather belt with embossed detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Upgrade your everyday collection with this tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italian Leather Derby Dress Shoe | Prindo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def pre_process(text):\r\n",
    "    # lowercase\r\n",
    "    text=text.lower()\r\n",
    "    \r\n",
    "    #remove tags\r\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\r\n",
    "    \r\n",
    "    # remove special characters and digits\r\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\r\n",
    "    \r\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "df['sentences'] = df['sentences'].apply(lambda x:pre_process(x))\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           sentences\n",
       "0             stretch cotton v neck t shirt dredosos\n",
       "1  this t shirt by hugo is crafted from cotton wi...\n",
       "2                  leather belt with embossed detail\n",
       "3  upgrade your everyday collection with this tim...\n",
       "4            italian leather derby dress shoe prindo"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stretch cotton v neck t shirt dredosos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this t shirt by hugo is crafted from cotton wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leather belt with embossed detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>upgrade your everyday collection with this tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>italian leather derby dress shoe prindo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from sentence_transformers import SentenceTransformer, util\r\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\r\n",
    "\r\n",
    "corpus = df['sentences'].tolist()\r\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\r\n",
    "\r\n",
    "# Query sentences:\r\n",
    "queries = ['white shoes that are confortable to wear', 'causal trousers', 'a nice suit for a wedding',\r\n",
    "           'a dress for a summer evening walk on the beach']\r\n",
    "\r\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\r\n",
    "top_k = min(5, len(corpus))\r\n",
    "for query in queries:\r\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\r\n",
    "\r\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\r\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\r\n",
    "\r\n",
    "    print(\"\\n======================\")\r\n",
    "    print(\"Query:\", query)\r\n",
    "    print(\"Top 5 most similar sentences in corpus:\")\r\n",
    "\r\n",
    "    for score, idx in zip(top_results[0], top_results[1]): \r\n",
    "        print(corpus[idx][:200], \"(Score: {:.4f})\".format(score))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======================\n",
      "Query: white shoes that are confortable to wear\n",
      "Top 5 most similar sentences in corpus:\n",
      "modern sneakers by boss crafted with uppers in nappa leather suede and structured fabric featuring embossed branding and pop color accents at the midsole and heel counter this running inspired pair is (Score: 0.7399)\n",
      "low top sneakers in mixed materials (Score: 0.7361)\n",
      "running style sneakers in tonal nappa leather and mesh (Score: 0.7302)\n",
      "directional sneakers by hugo set on an eva rubber sole with a chunky silhouette designed with perforated and rubberized trims these lightweight sneakers feature a knitted sock bungee cord style laces  (Score: 0.7293)\n",
      "running style sneakers with knitted upper and vibram sole (Score: 0.7283)\n",
      "\n",
      "======================\n",
      "Query: causal trousers\n",
      "Top 5 most similar sentences in corpus:\n",
      "versatile pants by boss menswear created in stretch fabric with a generous dose of virgin wool tapering through the leg these contemporary pants are designed with a pleated front cropped length and tu (Score: 0.6798)\n",
      "formal pants by hugo menswear delivered in an extra slim fit for a defined silhouette these distinctive pants are crafted in a virgin wool blend with two way stretch offering ultimate flexibility and  (Score: 0.6768)\n",
      "modern pants by hugo menswear with a tapered leg and a regular rise these pants are created in stretch jersey with a melange appearance and topped with an elasticated waistband side pockets and a draw (Score: 0.6530)\n",
      "formal pants by hugo menswear cut to an ultra narrow fit created in virgin wool for mid weight warmth these pants feature a fresh take on the windowpane check add color and unconventional character to (Score: 0.6492)\n",
      "versatile pants in virgin wool by boss menswear these formal pants offer a defined fit with a crisp front crease straight leg and regular rise combine them with the matching boss jacket for refined bu (Score: 0.6484)\n",
      "\n",
      "======================\n",
      "Query: a nice suit for a wedding\n",
      "Top 5 most similar sentences in corpus:\n",
      "a contemporary tuxedo by boss menswear cut to a defined silhouette in mid weight fabric with a touch of wool fully lined for elevated comfort this dinner suit features silk trims at the shawl lapels a (Score: 0.7058)\n",
      "a two piece tuxedo by boss menswear cut to a narrow fit for a sharp silhouette this fully lined suit is crafted in virgin wool and trimmed with silk at the shawl lapels pockets buttons and pant seams  (Score: 0.6964)\n",
      "slim fit tuxedo with silk trims and pocket square (Score: 0.6954)\n",
      "a refined tuxedo by boss menswear crafted in virgin wool with a serge weave this evening suit is offered in a defined fit and trimmed with tonal silk for an elegant touch build a cutting edge look by  (Score: 0.6779)\n",
      "a two piece tuxedo by boss menswear crafted in virgin wool with a melange surface for added interest cut to a defined silhouette this tuxedo suit is trimmed with contrast silk at the shawl lapels pock (Score: 0.6649)\n",
      "\n",
      "======================\n",
      "Query: a dress for a summer evening walk on the beach\n",
      "Top 5 most similar sentences in corpus:\n",
      "short sleeved dress with sparkly pleated skirt (Score: 0.5366)\n",
      "long length sleeveless dress in silk with waterfall front (Score: 0.5312)\n",
      "tie neck evening dress in lustrous fabric (Score: 0.5299)\n",
      "slim fit dress with rear cut out detail (Score: 0.5114)\n",
      "long sleeved dress in floral print twill (Score: 0.5099)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "3fa4fbff26baf5372c1227c893813242fd1c5dcfd93352f945b61348dd56c099"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}